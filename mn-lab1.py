# -*- coding: utf-8 -*-
"""Copia de Lab2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KeT01gcTyiDKLlxMgOrpOagFKDwiXcQG
"""

!pip install -U fortran-magic

# Commented out IPython magic to ensure Python compatibility.
!pip install -U fortran-magic
# %matplotlib inline
# %load_ext fortranmagic

import sys; sys.path.append('..')

import pandas as pd
import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt
import seaborn as sns

mpl.rc('figure', figsize=(12, 7))

ran_the_first_cell = True

jan2017 = pd.to_datetime(['2017-01-03 00:00:00+00:00',
 '2017-01-04 00:00:00+00:00',
 '2017-01-05 00:00:00+00:00',
 '2017-01-06 00:00:00+00:00',
 '2017-01-09 00:00:00+00:00',
 '2017-01-10 00:00:00+00:00',
 '2017-01-11 00:00:00+00:00',
 '2017-01-12 00:00:00+00:00',
 '2017-01-13 00:00:00+00:00',
 '2017-01-17 00:00:00+00:00',
 '2017-01-18 00:00:00+00:00',
 '2017-01-19 00:00:00+00:00',
 '2017-01-20 00:00:00+00:00',
 '2017-01-23 00:00:00+00:00',
 '2017-01-24 00:00:00+00:00',
 '2017-01-25 00:00:00+00:00',
 '2017-01-26 00:00:00+00:00',
 '2017-01-27 00:00:00+00:00',
 '2017-01-30 00:00:00+00:00',
 '2017-01-31 00:00:00+00:00',
 '2017-02-01 00:00:00+00:00'])
calendar = jan2017.values.astype('datetime64[D]')

event_dates = pd.to_datetime(['2017-01-06 00:00:00+00:00',
                             '2017-01-07 00:00:00+00:00',
                             '2017-01-08 00:00:00+00:00']).values.astype('datetime64[D]')
event_values = np.array([10, 15, 20])

"""<center>
  <h1>The PyData Toolbox</h1>
  <h3>Scott Sanderson (Twitter: @scottbsanderson, GitHub: ssanderson)</h3>
  <h3><a href="https://github.com/ssanderson/pydata-toolbox">https://github.com/ssanderson/pydata-toolbox</a></h3>
</center>

# About Me:

<img src="https://raw.githubusercontent.com/ssanderson/pydata-toolbox/master/notebooks/images/me.jpg" alt="Drawing" style="width: 300px;"/>

- Senior Engineer at [Quantopian](www.quantopian.com)
- Background in Mathematics and Philosophy
- **Twitter:** [@scottbsanderson](https://twitter.com/scottbsanderson)
- **GitHub:** [ssanderson](github.com/ssanderson)

## Outline

- Built-in Data Structures
- Numpy `array`
- Pandas `Series`/`DataFrame`
- Plotting and "Real-World" Analyses

# Data Structures

> Rule 5. Data dominates. If you've chosen the right data structures and organized things well, the algorithms
will almost always be self-evident. Data structures, not algorithms, are central to programming.

- *Notes on Programming in C*, by Rob Pike.

# Lists
"""

assert ran_the_first_cell, "Oh noes!"

l = [1, 'two', 3.0, 4, 5.0, "six"]
l

# Lists can be indexed like C-style arrays.
first = l[0]
second = l[1]
print("first:", first)
print("second:", second)

# Negative indexing gives elements relative to the end of the list.
last = l[-1]
penultimate = l[-2]
print("last:", last)
print("second to last:", penultimate)

# Lists can also be sliced, which makes a copy of elements between
# start (inclusive) and stop (exclusive)
sublist = l[1:3]
sublist

# l[:N] is equivalent to l[0:N].
first_three = l[:3]
first_three

# l[3:] is equivalent to l[3:len(l)].
after_three = l[3:]
after_three

# There's also a third parameter, "step", which gets every Nth element.
l = ['a', 'b', 'c', 'd', 'e', 'f', 'g','h']
l[1:7:2]

# This is a cute way to reverse a list.
l[::-1]

# Lists can be grown efficiently (in O(1) amortized time).
l = [1, 2, 3, 4, 5]
print("Before:", l)
l.append('six')
print("After:", l)

# Comprehensions let us perform elementwise computations.
l = [1, 2, 3, 4, 5]
[x * 2 for x in l]

"""## Review: Python Lists

- Zero-indexed sequence of arbitrary Python values.
- Slicing syntax: `l[start:stop:step]` copies elements at regular intervals from `start` to `stop`.
- Efficient (`O(1)`) appends and removes from end.
- Comprehension syntax: `[f(x) for x in l if cond(x)]`.

# Dictionaries
"""

# Dictionaries are key-value mappings.
philosophers = {'David': 'Hume', 'Immanuel': 'Kant', 'Bertrand': 'Russell'}
philosophers

# Like lists, dictionaries are size-mutable.
philosophers['Ludwig'] = 'Wittgenstein'
philosophers

del philosophers['David']
philosophers

# No slicing.
# philosophers['Bertrand':'Immanuel']}
for k in philosophers:
  print('{0} {1}'.format(k, philosophers[k]))

"""## Review: Python Dictionaries

- Unordered key-value mapping from (almost) arbitrary keys to arbitrary values.
- Efficient (`O(1)`) lookup, insertion, and deletion.
- No slicing (would require a notion of order).

<center><img src="https://raw.githubusercontent.com/ssanderson/pydata-toolbox/master/notebooks/images/pacino.gif" alt="Drawing" style="width: 100%;"/></center>
"""

4 * "a"

# Suppose we have some matrices...
a = [[1, 2, 3],
     [2, 3, 4],
     [5, 6, 7],
     [1, 1, 1]]

b = [[1, 2, 3, 4],
     [2, 3, 4, 5]]

def matmul(A, B):
    """Multiply matrix A by matrix B."""
    rows_out = len(A)
    cols_out = len(B[0])
    out = [[0 for col in range(cols_out)] for row in range(rows_out)]

    for i in range(rows_out):
        for j in range(cols_out):
            for k in range(len(B)):
                out[i][j] += A[i][k] * B[k][j]
    return out

"""<center><img src="https://raw.githubusercontent.com/ssanderson/pydata-toolbox/master/notebooks/images/gross.gif" alt="Drawing" style="width: 50%;"/></center>

"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# matmul(a, b)

"""**My own example 0 - cpu info**"""

!cat /proc/cpuinfo

"""**My own example 1 - Changing in matmul(A, B) Python len(B) (# of rows of B) for len(A[0]) (# of columns of A)**"""

def matmulUpdateA(A, B):
  ''' Multiplica matriz A por matriz B '''
  rows_out = len(A)
  cols_out = len(A[0])
  out =[[0 for col in range(cols_out)] for row in range(rows_out)]

  for i in range(rows_out):
        for j in range(cols_out):
            for k in range(len(B)):
                out[i][j] += A[i][k] * B[k][j]
  return out

# Commented out IPython magic to ensure Python compatibility.
# %%time
# try:
#   matmulUpdateA(a, b)
# except IndexError:
#   print('Escoja mejor las dimensiones.')

"""**My own example 2 - Verifiying error with in matmul(A, B) Python with the original matrices when changing len(B) (# of rows of B) for len(A[0]) (# of colums of A)**"""

matmulUpdate(a,b)

def matmulUpdateB(A, B):
  ''' Multiplica matriz A por matriz B '''
  rows_out = len(A)
  cols_out = len(A)
  #matrix_out =[[0 for col in range(cols_out)] for row in range(rows_out)]

  matrix_out = []
#'''
  for row in range(rows_out):
    row_list = []
    for col in range(cols_out):
      row_list.append(0)
    matrix_out.append(row_list)
#'''
  for i in range(rows_out):
        for j in range(cols_out):
          try:
            for k in range(len(B)):
                matrix_out[i][j] += A[i][k] * B[k][j]
          except IndexError:
            print('Index Error: Use otras dimensiones de matriz \n\n')
            return
  return matrix_out

# Commented out IPython magic to ensure Python compatibility.
# %%time
# matmulUpdateB(a, b)

"""**My own example 3 - Chekcing the mtarix multiplication compatibility condition  len(A[0]) == len(B)**"""

def matmul(A, B):
    """Multiply matrix A by matrix B."""
    rows_out = len(A)
    cols_out = len(B[0])
    out = [[0 for col in range(cols_out)] for row in range(rows_out)]
    if(len(A[0]) == len(B)):
      for i in range(rows_out):
          for j in range(cols_out):
              for k in range(len(B)):
                  out[i][j] += A[i][k] * B[k][j]
    else:
      print("Number of columns in A doesn't match with number of rows of B")
    return out

def matmulUpdateC(A, B):
  # Multiplica matriz A por matriz B.
  if len(A[0]) == len(B):
    rows_out = len(A)
    cols_out = len(B)
    matrix_out = [[0 for col in range(cols_out)] for row in range(rows_out)]

    for i in range(rows_out):
      for j in range(cols_out):
        for k in range(len(A[0])):
          matrix_out[i][j] += A[i][k] * B[k][j]
    return matrix_out

# Commented out IPython magic to ensure Python compatibility.
# %%time
# matmulUpdateC(a, b)

"""**My own example 4 -  Verifiying error with in matmul(A, B) Python when checking the mtarix multiplication compatibility condition  len(A[0]) == len(B)**"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# matmul(a,b)

def matmulUpdateD(A, B):
  # Multiplica la matriz A por la matriz B.
  if len(A[0]) != len(B):
    return print('\n\n Multiplicaci√≥n imposible por incompatiblidad de dimensiones.\n\n')
  else:
    rows_out = len(A)
    cols_out = len(B)
    matrix_out = [[0 for col in range(cols_out)] for row in range(rows_out)]

    for i in range(rows_out):
      for j in range(cols_out):
        for k in range(len(A[0])):
          matrix_out[i][j] += A[i][k] * B[k][j]
    return matrix_out

# Commented out IPython magic to ensure Python compatibility.
# %%time
# matmulUpdateD(a, b)

"""**My own example 5 - Deifining A and B that are compatible for multiplcation**"""

a=[2,4],[5,7]
b=[1,3],[6,8]

matmul(a,b)

"""**My own example 6 - Runinng the correct Python matrix multiplication code with the matrices with dimensions compatible for multiplication.**"""

import random

random.normalvariate(0,1)

def random_matrix(m, n):
    out = []
    for row in range(m):
        out.append([random.random() for _ in range(n)])
    return out

randm = random_matrix(2, 3)
randm

# Commented out IPython magic to ensure Python compatibility.
# %%time
# randA = random_matrix(600, 100)
# randB = random_matrix(100, 600)
# x = matmul(randA, randB)

"""**My own example 7 - Running 10 times matmul(randa, randb) with randa and randb a randon matrices of 600 x 100 and 100 x 600 and calulating the average execution time**"""

import time as tm

def mt_multi_time(matA, matB, rep):
  tm_sum = 0

  for i in range(rep):
    st = tm.process_time()

    response = matmulUpdateD(matA, matB)

    end = tm.process_time()

    tm_passed = end -st
    tm_sum += tm_passed

    print('Execution {0} -> {1} segundos'. format(i+1, tm_passed))

  avr = tm_sum/rep
  print('Promedio Python:', avr, ' segundos.')
  return avr

randmA = random_matrix(600, 100)
randmB = random_matrix(100, 600)

avr_py = mt_multi_time(randmA, randmB, 10)

"""**My own example 8 - Creating the average execution time data frame and adding Python's average execution time**"""

import pandas as pd

def add_avr_data(df, lan, avr):
  new_df = pd.DataFrame({'Lenguaje': [lan], 'Promedio (s)':[avr]})
  return df.append(new_df, ignore_index = True)

language_average = pd.DataFrame({'Lenguaje':[], 'Promedio (s)':[]})
language_average = add_avr_data(language_average, 'Python', avr_py)
language_average

"""**My own example 9 - Running 10 times randa and randb mutiplicaction as NumPy arrays  adding NumPy's average execution time**"""

import numpy as np

# Generar matrices aleatorias como arrays de NumPy
def generate_numpy_matrices(rows_a, cols_a, rows_b, cols_b):
    randa_np = np.random.randint(0, 10, (rows_a, cols_a))
    randb_np = np.random.randint(0, 10, (rows_b, cols_b))
    return randa_np, randb_np

# Commented out IPython magic to ensure Python compatibility.
# # Medir el tiempo de ejecuci√≥n para 10 iteraciones de la multiplicaci√≥n de matrices utilizando NumPy
# %%time
# for _ in range(10):
#     randa_np, randb_np = generate_numpy_matrices(600, 100, 100, 600)
#     np.dot(randa_np, randb_np)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# randa = random_matrix(600, 100)
# randb = random_matrix(100, 600)
# x = matmul(randa, randb)

# Maybe that's not that bad?  Let's try a simpler case.
def python_dot_product(xs, ys):
    return sum(x * y for x, y in zip(xs, ys))

# Commented out IPython magic to ensure Python compatibility.
# %%fortran
# subroutine fortran_dot_product(xs, ys, result)
#     double precision, intent(in) :: xs(:)
#     double precision, intent(in) :: ys(:)
#     double precision, intent(out) :: result
# 
#     result = sum(xs * ys)
# end

list_data = [float(i) for i in range(100000)]
array_data = np.array(list_data)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# python_dot_product(list_data, list_data)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# fortran_dot_product(array_data, array_data)

"""<center><img src="https://raw.githubusercontent.com/ssanderson/pydata-toolbox/master/notebooks/images/sloth.gif" alt="Drawing" style="width: 1080px;"/></center>

**My own example 10 - Deifining A (2x2)  and B (2x2)**
"""

a=[3,5],[1,4]
b=[6,2],[3,8]

A = [[12.0, 43.0],
     [25.0, 17.0]]

B = [[2.0, 13.0],
     [26.0, 58.0]]

"""**My own example 11 - Defining Fortran subroutine matmul(A,B) for 2x2 matrices**"""

# Commented out IPython magic to ensure Python compatibility.
# %%fortran
# subroutine matmul_fortran(matA, matB, result)
#     real, intent(in) :: matA(2,2)
#     real, intent(in) :: matB(2,2)
#     real, intent(out) :: result(2,2)
# 
#     ! Compatible matrix -> # A's columns = # B's rows
# 
#     do i=1,2
#       do j=1,2
#         do k=1,2
#           result(i,j) = result(i,j) + matA(i,k) * matB(k,j)
#         end do
#       end do
#     end do
# end

"""**My own example 12 -Run Fortran subroutine matmul(A,B) with a and b 2x2 matrices**"""

anp = np.array(A)
bnp = np.array(B)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# matmul_fortran(anp, bnp)

"""**My own example 13 - Defining Fortran subroutine matmul(A,B) for 600x100 and 100x600 matrices**"""

# Commented out IPython magic to ensure Python compatibility.
# %%fortran
# subroutine matmul_fortran_rectangle(matA, matB, result)
#     real, intent(in) :: matA(600,100)
#     real, intent(in) :: matB(100,600)
#     real, intent(out) :: result(600,600)
# 
#     ! Compatible matrix -> # A's columns = # B's rows
# 
#     ! Result matrix has:
#     ! Rows = rows of matrix A
#     ! Columns = columns of matrix B
# 
#     do i=1,600
#       do j=1,600
#         do k=1,100
#           result(i,j) = result(i,j) + matA(i,k) * matB(k,j)
#         end do
#       end do
#     end do
# end

"""**My own example 14 -Run Fortran subroutine matmul(A,B) with 600x100 and 100x600 matrices**"""

randmA1 = random_matrix(600, 100)
randmB1 = random_matrix(100, 600)

arnp = np.array(randmA1)
brnp = np.array(randmB1)
matmul_fortran_rectangle(arnp,brnp)

"""**My own example 15 - Running 10 times the  Fortran subroutine matmul(A,B) with 600x100 and 100x600 matrices and adding Fortran magic average execution time to the data frame**"""

def mt_multi_time_fortran(matA, matB, rep):
  tm_sum = 0

  for i in range(rep):
    st = tm.process_time()

    matmul_fortran_rectangle(matA,matB)

    end = tm.process_time()

    tm_passed = end - st
    tm_sum += tm_passed

    print('Execution {0} -> {1} seconds'.format(i+1, tm_passed))

  avr = tm_sum/rep
  print('Average Fortran in Python:',avr, 'seconds')
  return avr

avr_fortran_A = mt_multi_time_fortran(randmA, randmB, 10)

print('\n')
language_average = add_avr_data(language_average, 'Fortranmagic', avr_fortran_A)
language_average

"""**My own example 16 - Creating a  Fortran program that mutiplies 10 times A(600x100) and  B (100x600) matrices**"""



"""**My own example 17 - Running the Fortran program that mutiplies 10 times A(600x100) and  B (100x600) matrices**"""



"""**My own example 18 - Adding Fortran average execution time to the data frame**"""



"""**My own example 19 - Creating a c program that mutiplies 10 times A(600x100) and  B (100x600) matrices**"""



"""**My own example 20 - Running the c program that mutiplies 10 times A(600x100) and  B (100x600) matrices**"""



"""**My own example 21 - Adding c average execution time to the data frame**"""



"""**My own example 22 - Creating a C++ program that mutiplies 10 times A(600x100) and  B (100x600) matrices**"""



"""**My own example 23 - Running the C++ program that mutiplies 10 times A(600x100) and  B (100x600) matrices**"""



"""**My own example 24 - Adding C++ average execution time to the data frame**"""



"""**My own example 25 - Creating a Java program that mutiplies 10 times A(600x100) and  B (100x600) matrices**"""



"""**My own example 26 - Running the Java program that mutiplies 10 times A(600x100) and  B (100x600) matrices**"""



"""**My own example 27 - Adding Java average execution time to the data frame**"""



"""# **My own example 28 - Creating a Javascript program that mutiplies 10 times A(600x100) and  B (100x600) matrices**"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile matMul.js
# 
# const fs = require("fs");
# const {performance} = require('perf_hooks');
# 
# const matMultiplication = (matA, matB, result, n, m)=>{
#   // Los arreglos se pasan por defecto por referencia.
#   // Las filas de la matriz resultado son las de la matriz A
#   // y sus columnas son las de la matriz B.
# 
#   for(let i=0; i<n; i++){
#     for(let j=0; j<n; j++){
#       for(let k=0; k<m; k++){
#         result[i][j] += matA[i][k] * matB[k][j];
#       }
#     }
#   }
# }
# 
# const multAverage = (matA, matB, result, n, m, rep) => {
#   let average = 0;
#   let start = 0;
#   let end = 0;
#   let execution = 0;
# 
#   for(let i = 0; i < rep; i++){
#     start = performance.now();
#     matMultiplication(matA, matB, result, n, m);
#     end = performance.now();
# 
#     execution = end - start; // medida en milisengundos.
#     average += execution;
#     console.log(`Execution ${i+1} -> ${execution/1000} segundos.`);
#   }
#   average /= rep;
#   return average/1000;
# }
# 
# const randomNumber = (mat, n, m) => {
#   const min = 1;
#   const max = 100000;
#   return Math.floor(Math.random() * (max - min + 1)) + min
# }
# 
# const matMul = () => {
#   const n = 600;
#   const m = 100;
#   const rep = 10;
# 
#   // Se llena la matriz.
#   const matA = new Array(n).fill(new Array(m).fill(randomNumber()));
#   const matB = new Array(m).fill(new Array(n).fill(randomNumber()));
#   const result = new Array(n).fill(new Array(n).fill(0));
# 
#   // Repeticiones de multiplicaci√≥n de matrices.
#   const average = multAverage(matA, matB, result, n, m, rep);
# 
#   console.log(`Average Javascript: ${average} segundos.`);
# 
#   // Escribir promedio en el archivo.
#   fs.writeFile("js_promedio.txt", `${average}`, function(err){
#     if (err){
#       console.log("Error escribiendo el archivo:", err);
#     }
#   });
# }
# matMul();

"""**My own example 29 - Running the Javascript program that mutiplies 10 times A(600x100) and  B (100x600) matrices**"""

!node matMul.js

"""**My own example 30 - Adding Javascript average execution time to the data frame**"""

js_file = open('js_promedio.txt', 'r')
avr_js = float(js_file.readline())
language_average = add_avr_data(language_average, 'Javascript', avr_js)
language_average

"""**My own example 31 - Finding the minimun average esecuiton time in the data frame**"""



"""**My own example 32 - Adding the Speed factor columne to the data frame**

**My own example 33 - Sorting the the data frame by average execution time**
"""



"""## Why is the Python Version so Much Slower?"""

# Dynamic typing.
def mul_elemwise(xs, ys):
    return [x * y for x, y in zip(xs, ys)]

mul_elemwise([1, 2, 3, 4], [1, 2 + 0j, 3.0, 'four'])
#[type(x) for x in _]

# Interpretation overhead.
source_code = 'a + b * c'
bytecode = compile(source_code, '', 'eval')
import dis; dis.dis(bytecode)

"""## Why is the Python Version so Slow?
- Dynamic typing means that every single operation requires dispatching on the input type.
- Having an interpreter means that every instruction is fetched and dispatched at runtime.
- Other overheads:
  - Arbitrary-size integers.
  - Reference-counted garbage collection.

> This is the paradox that we have to work with when we're doing scientific or numerically-intensive Python. What makes Python fast for development -- this high-level, interpreted, and dynamically-typed aspect of the language -- is exactly what makes it slow for code execution.

- Jake VanderPlas, [*Losing Your Loops: Fast Numerical Computing with NumPy*](https://www.youtube.com/watch?v=EEUXKG97YRw)

# What Do We Do?

<center><img src="https://raw.githubusercontent.com/ssanderson/pydata-toolbox/master/notebooks/images/runaway.gif" alt="Drawing" style="width: 50%;"/></center>

<center><img src="https://raw.githubusercontent.com/ssanderson/pydata-toolbox/master/notebooks/images/thisisfine.gif" alt="Drawing" style="width: 1080px;"/></center>

- Python is slow for numerical computation because it performs dynamic dispatch on every operation we perform...

- ...but often, we just want to do the same thing over and over in a loop!

- If we don't need Python's dynamicism, we don't want to pay (much) for it.

- **Idea:** Dispatch **once per operation** instead of **once per element**.
"""

import numpy as np

data = np.array([1, 2, 3, 4])
data

data + data

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # Naive dot product
# (array_data * array_data).sum()

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # Built-in dot product.
# array_data.dot(array_data)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# fortran_dot_product(array_data, array_data)

# Numpy won't allow us to write a string into an int array.
data[0] = "foo"

# We also can't grow an array once it's created.
data.append(3)

# We **can** reshape an array though.
two_by_two = data.reshape(2, 2)
two_by_two

"""Numpy arrays are:

- Fixed-type

- Size-immutable

- Multi-dimensional

- Fast\*

\* If you use them correctly.

# What's in an Array?
"""

arr = np.array([1, 2, 3, 4, 5, 6], dtype='int16').reshape(2, 3)
print("Array:\n", arr, sep='')
print("===========")
print("DType:", arr.dtype)
print("Shape:", arr.shape)
print("Strides:", arr.strides)
print("Data:", arr.data.tobytes())

"""# Core Operations

- Vectorized **ufuncs** for elementwise operations.
- Fancy indexing and masking for selection and filtering.
- Aggregations across axes.
- Broadcasting

# UFuncs

UFuncs (universal functions) are functions that operate elementwise on one or more arrays.
"""

data = np.arange(15).reshape(3, 5)
data

# Binary operators.
data * data

# Unary functions.
np.sqrt(data)

# Comparison operations
(data % 3) == 0

# Boolean combinators.
((data % 2) == 0) & ((data % 3) == 0)

# as of python 3.5, @ is matrix-multiply
data @ data.T

"""# UFuncs Review

- UFuncs provide efficient elementwise operations applied across one or more arrays.
- Arithmetic Operators (`+`, `*`, `/`)
- Comparisons (`==`, `>`, `!=`)
- Boolean Operators (`&`, `|`, `^`)
- Trigonometric Functions (`sin`, `cos`)
- Transcendental Functions (`exp`, `log`)

# Selections

We often want to perform an operation on just a subset of our data.
"""

sines = np.sin(np.linspace(0, 3.14, 10))
cosines = np.cos(np.linspace(0, 3.14, 10))
sines

# Slicing works with the same semantics as Python lists.
sines[0]

sines[:3]  # First three elements

sines[5:]  # Elements from 5 on.

sines[::2]  # Every other element.

# More interesting: we can index with boolean arrays to filter by a predicate.
print("sines:\n", sines)
print("sines > 0.5:\n", sines > 0.5)
print("sines[sines > 0.5]:\n", sines[sines > 0.5])

# We index with lists/arrays of integers to select values at those indices.
print(sines)
sines[[0, 4, 7]]

# Index arrays are often used for sorting one or more arrays.
unsorted_data = np.array([1, 3, 2, 12, -1, 5, 2])

sort_indices = np.argsort(unsorted_data)
sort_indices

unsorted_data[sort_indices]

market_caps = np.array([12, 6, 10, 5, 6])  # Presumably in dollars?
assets = np.array(['A', 'B', 'C', 'D', 'E'])

# Sort assets by market cap by using the permutation that would sort market caps on ``assets``.
sort_by_mcap = np.argsort(market_caps)
assets[sort_by_mcap]

# Indexers are also useful for aligning data.
print("Dates:\n", repr(event_dates))
print("Values:\n", repr(event_values))
print("Calendar:\n", repr(calendar))

print("Raw Dates:", event_dates)
print("Indices:", calendar.searchsorted(event_dates))
print("Forward-Filled Dates:", calendar[calendar.searchsorted(event_dates)])

"""On multi-dimensional arrays, we can slice along each axis independently."""

data = np.arange(25).reshape(5, 5)
data

data[:2, :2]  # First two rows and first two columns.

data[:2, [0, -1]]  # First two rows, first and last columns.

data[(data[:, 0] % 2) == 0]  # Rows where the first column is divisible by two.

"""# Selections Review

- Indexing with an integer removes a dimension.
- Slicing operations work on Numpy arrays the same way they do on lists.
- Indexing with a boolean array filters to True locations.
- Indexing with an integer array selects indices along an axis.
- Multidimensional arrays can apply selections independently along different axes.

## Reductions

Functions that reduce an array to a scalar.

$Var(X) = \frac{1}{N}\sqrt{\sum_{i=1}^N (x_i - \bar{x})^2}$
"""

def variance(x):
    return ((x - x.mean()) ** 2).sum() / len(x)

variance(np.random.standard_normal(1000))

"""- `sum()` and `mean()` are both **reductions**.

- In the simplest case, we use these to reduce an entire array into a single value...
"""

data = np.arange(30)
data.mean()

"""- ...but we can do more interesting things with multi-dimensional arrays."""

data = np.arange(30).reshape(3, 10)
data

data.mean()

data.mean(axis=0)

data.mean(axis=1)

"""## Reductions Review

- Reductions allow us to perform efficient aggregations over arrays.
- We can do aggregations over a single axis to collapse a single dimension.
- Many built-in reductions (`mean`, `sum`, `min`, `max`, `median`, ...).

# Broadcasting
"""

row = np.array([1, 2, 3, 4])
column = np.array([[1], [2], [3]])
print("Row:\n", row, sep='')
print("Column:\n", column, sep='')

row + column

"""<center><img src="https://raw.githubusercontent.com/ssanderson/pydata-toolbox/master/notebooks/images/broadcasting.png" alt="Drawing" style="width: 60%;"/></center>

<h5>Source: http://www.scipy-lectures.org/_images/numpy_broadcasting.png</h5>
"""

# Broadcasting is particularly useful in conjunction with reductions.
print("Data:\n", data, sep='')
print("Mean:\n", data.mean(axis=0), sep='')
print("Data - Mean:\n", data - data.mean(axis=0), sep='')

"""# Broadcasting Review

- Numpy operations can work on arrays of different dimensions as long as the arrays' shapes are still "compatible".
- Broadcasting works by "tiling" the smaller array along the missing dimension.
- The result of a broadcasted operation is always at least as large in each dimension as the largest array in that dimension.

# Numpy Review

- Numerical algorithms are slow in pure Python because the overhead dynamic dispatch dominates our runtime.

- Numpy solves this problem by:
  1. Imposing additional restrictions on the contents of arrays.
  2. Moving the inner loops of our algorithms into compiled C code.

- Using Numpy effectively often requires reworking an algorithms to use vectorized operations instead of for-loops, but the resulting operations are usually simpler, clearer, and faster than the pure Python equivalent.

<center><img src="https://raw.githubusercontent.com/ssanderson/pydata-toolbox/master/notebooks/images/unicorn.jpg" alt="Drawing" style="width: 75%;"/></center>

Numpy is great for many things, but...

- Sometimes our data is equipped with a natural set of **labels**:
  - Dates/Times
  - Stock Tickers
  - Field Names (e.g. Open/High/Low/Close)

- Sometimes we have **more than one type of data** that we want to keep grouped together.
  - Tables with a mix of real-valued and categorical data.

- Sometimes we have **missing** data, which we need to ignore, fill, or otherwise work around.

<center><img src="https://raw.githubusercontent.com/ssanderson/pydata-toolbox/master/notebooks/images/panda-wrangling.gif" alt="Drawing" style="width: 75%;"/></center>

<center><img src="https://raw.githubusercontent.com/ssanderson/pydata-toolbox/master/notebooks/images/pandas_logo.png" alt="Drawing" style="width: 75%;"/></center>

Pandas extends Numpy with more complex data structures:

- `Series`: 1-dimensional, homogenously-typed, labelled array.
- `DataFrame`: 2-dimensional, semi-homogenous, labelled table.

Pandas also provides many utilities for:
- Input/Output
- Data Cleaning
- Rolling Algorithms
- Plotting

# Selection in Pandas
"""

s = pd.Series(index=['a', 'b', 'c', 'd', 'e'], data=[1, 2, 3, 4, 5])
s

# There are two pieces to a Series: the index and the values.
print("The index is:", s.index)
print("The values are:", s.values)

# We can look up values out of a Series by position...
s.iloc[0]

# ... or by label.
s.loc['a']

# Slicing works as expected...
s.iloc[:2]

# ...but it works with labels too!
s.loc[:'c']

# Fancy indexing works the same as in numpy.
s.iloc[[0, -1]]

# As does boolean masking.
s.loc[s > 2]

# Element-wise operations are aligned by index.
other_s = pd.Series({'a': 10.0, 'c': 20.0, 'd': 30.0, 'z': 40.0})
other_s

s + other_s

# We can fill in missing values with fillna().
(s + other_s).fillna(0.0)

# Most real datasets are read in from an external file format.
aapl = pd.read_csv('AAPL.csv', parse_dates=['Date'], index_col='Date')
aapl.head()

# Slicing generalizes to two dimensions as you'd expect:
aapl.iloc[:2, :2]

aapl.loc[pd.Timestamp('2010-02-01'):pd.Timestamp('2010-02-04'), ['Close', 'Volume']]

"""# Rolling Operations

<center><img src="https://raw.githubusercontent.com/ssanderson/pydata-toolbox/master/notebooks/images/rolling.gif" alt="Drawing" style="width: 75%;"/></center>
"""

aapl.rolling(5)[['Close', 'Adj Close']].mean().plot();

# Drop `Volume`, since it's way bigger than everything else.
aapl.drop('Volume', axis=1).resample('2W').max().plot();

# 30-day rolling exponentially-weighted stddev of returns.
aapl['Close'].pct_change().ewm(span=30).std().plot();

"""# "Real World" Data"""

from demos.avocados import read_avocadata

avocados = read_avocadata('2014', '2016')
avocados.head()

# Unlike numpy arrays, pandas DataFrames can have a different dtype for each column.
avocados.dtypes

# What's the regional average price of a HASS avocado every day?
hass = avocados[avocados.Variety == 'HASS']
hass.groupby(['Date', 'Region'])['Weighted Avg Price'].mean().unstack().ffill().plot();

def _organic_spread(group):

    if len(group.columns) != 2:
        return pd.Series(index=group.index, data=0.0)

    is_organic = group.columns.get_level_values('Organic').values.astype(bool)
    organics = group.loc[:, is_organic].squeeze()
    non_organics = group.loc[:, ~is_organic].squeeze()
    diff = organics - non_organics
    return diff

def organic_spread_by_region(df):
    """What's the difference between the price of an organic
    and non-organic avocado within each region?
    """
    return (
        df
        .set_index(['Date', 'Region', 'Organic'])
         ['Weighted Avg Price']
        .unstack(level=['Region', 'Organic'])
        .ffill()
        .groupby(level='Region', axis=1)
        .apply(_organic_spread)
    )

organic_spread_by_region(hass).plot();
plt.gca().set_title("Daily Regional Organic Spread");
plt.legend(bbox_to_anchor=(1, 1));

spread_correlation = organic_spread_by_region(hass).corr()
spread_correlation

import seaborn as sns
grid = sns.clustermap(spread_correlation, annot=True)
fig = grid.fig
axes = fig.axes
ax = axes[2]
ax.set_xticklabels(ax.get_xticklabels(), rotation=45);

"""# Pandas Review

- Pandas extends numpy with more complex datastructures and algorithms.
- If you understand numpy, you understand 90% of pandas.
- `groupby`, `set_index`, and `unstack` are powerful tools for working with categorical data.
- Avocado prices are surprisingly interesting :)

# Thanks!
"""